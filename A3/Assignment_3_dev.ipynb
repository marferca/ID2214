{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 Group no. [enter]\n",
    "### Project members: \n",
    "[Enter Name, email]...\n",
    "\n",
    "### Declaration\n",
    "By submitting this solution, it is hereby declared that all individuals listed above have contributed to the solution, either with code that appear in the final solution below, or with code that has been evaluated and compared to the final solution, but for some reason has been excluded. It is also declared that all project members fully understand all parts of the final solution and can explain it upon request.\n",
    "\n",
    "It is furthermore declared that the code below is a contribution by the project members only, and specifically that no part of the solution has been copied from any other source (except for lecture slides at the course ID2214) and no part of the solution has been provided by someone not listed as project member above.\n",
    "\n",
    "It is furthermore declared that it has been understood that no other library/package than the Python 3 standard library, NumPy, pandas and time may be used in the solution for this assignment.\n",
    "\n",
    "### Instructions\n",
    "All assignments starting with number 1 below are mandatory. Satisfactory solutions\n",
    "will give 1 point (in total). If they in addition are good (all parts work more or less \n",
    "as they should), completed on time (submitted before the deadline in Canvas) and according\n",
    "to the instructions, together with satisfactory solutions of assignments starting with \n",
    "number 2 below, then the assignment will receive 2 points (in total).\n",
    "\n",
    "It is highly recommended that you do not develop the code directly within the notebook\n",
    "but that you copy the comments and test cases to your regular development environment\n",
    "and only when everything works as expected, that you paste your functions into this\n",
    "notebook, do a final testing (all cells should succeed) and submit the whole notebook \n",
    "(a single file) in Canvas (do not forget to fill in your group number and names above).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NumPy, pandas and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reused functions from Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Copy and paste functions from Assignment 1 here that you need for this assignment\n",
    "\n",
    "# Binning functions -------------------------------------------------------------------------\n",
    "def create_bins(df, nobins, bintype=\"equal-width\"):\n",
    "    df_tmp = df.drop([\"CLASS\",\"ID\"], axis=1, errors=\"ignore\").select_dtypes(include=[\"int\",\"float\"])\n",
    "\n",
    "    binning = {}\n",
    "    df_out = pd.DataFrame()\n",
    "    for col in df_tmp.columns:\n",
    "        if (bintype == \"equal-width\"):\n",
    "            res_tmp, bins_tmp = pd.cut(df_tmp[col], nobins, retbins=True, labels=False, duplicates=\"drop\")\n",
    "        elif (bintype == \"equal-size\"):\n",
    "            res_tmp, bins_tmp = pd.qcut(df_tmp[col], nobins, retbins=True, labels=False, duplicates=\"drop\")\n",
    "            \n",
    "        bins_tmp[0] = -np.inf # Set the first element of the binning list to -np.inf\n",
    "        bins_tmp[-1] = np.inf # Set the last element of the binning list to np.inf\n",
    "        \n",
    "        binning[col] = tuple(bins_tmp)\n",
    "        \n",
    "    df_out = apply_bins(df,binning) # Apply binning\n",
    "    return df_out,binning\n",
    "\n",
    "def apply_bins(df,binning):\n",
    "    df_out = df.copy()\n",
    "    for col in binning:\n",
    "        df_out[col] = pd.DataFrame(pd.cut(df_out[col],binning[col],labels=False, duplicates=\"drop\")).astype(\"category\")\n",
    "    return df_out\n",
    "# End of Binning functions ------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Imputation functions ----------------------------------------------------------------------\n",
    "def create_imputation(df):\n",
    "    df_tmp = df.copy()\n",
    "    \n",
    "    df_tmp_num = df_tmp.drop([\"CLASS\",\"ID\"], axis=1, errors=\"ignore\").select_dtypes(include=[\"int\",\"float\"]) # Select only numeric columns\n",
    "    df_mean = pd.DataFrame(df_tmp_num.mean())\n",
    "    df_tmp_num[(df_tmp_num.isna().all()).index[df_tmp_num.isna().all()]] = 0 # When all values are missing in a numeric column all values are replaced with by 0\n",
    "\n",
    "    df_tmp_obj = df_tmp.drop([\"CLASS\",\"ID\"], axis=1, errors=\"ignore\").select_dtypes(include=[\"object\",\"category\"]) # Select only object and categorical columns\n",
    "    df_mode = df_tmp_obj.mode().transpose()\n",
    "    df_tmp_obj[(df_tmp_obj.isna().all()).index[df_tmp_obj.isna().all()]] = \"\" # When all values are missing in a object or categorical column all values are replaced by \"\"\n",
    "\n",
    "    imputation = ((pd.concat([df_mean[0],df_mode[0]], axis=0)).fillna(0)).to_dict() # Create a mapping from column name to new value\n",
    "    \n",
    "    df_out = apply_imputation(df, imputation) # Apply imputation\n",
    "    return df_out,imputation\n",
    "\n",
    "def apply_imputation(df, imputation):\n",
    "    df_out = df.copy()\n",
    "    df_out.fillna(value=imputation, inplace=True) # Replace NaN values accoding with the dictionary imputation\n",
    "    return df_out\n",
    "# End of Imputation functions ---------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Brier score function ----------------------------------------------------------------------\n",
    "def brier_score(df,correctlabels):\n",
    "    cat = df.columns # Get categories (columns)\n",
    "    target = [(lab == cat).astype(float) for lab in correctlabels] # Get a matrix of targuet values from a list of correct labels \n",
    "    df_target = pd.DataFrame(target,columns=cat) # Matrix to dataframe\n",
    "    return ((((df - df_target).pow(2)).sum(axis=1)).sum())/len(df) # Calculate brier score from dataframes\n",
    "# End of brier score function ----------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Accuracy function -------------------------------------------------------------------------\n",
    "def accuracy(df,correctlabels):\n",
    "    predicted = df.idxmax(axis=1, skipna=True) # Index (column name) of first occurrence of maximum value\n",
    "    acc = sum(predicted == correctlabels)/len(correctlabels)\n",
    "    return acc\n",
    "# End of Accuracy function ------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# AUC function ------------------------------------------------------------------------------\n",
    "def auc(df,correctlabels):\n",
    "    cat = df.columns\n",
    "    target = [(lab == cat).astype(float) for lab in correctlabels]\n",
    "    df_target = pd.DataFrame(target, columns=cat)\n",
    "\n",
    "    AUC = 0\n",
    "    for col in df.columns:                       # For each class create a dictionary with a mapping from each score score:[num_pos,num_neg]\n",
    "        dic = {score:[0,0] for score in df[col]} # Initialize dictionary\n",
    "\n",
    "        for n in range(len(df[col])):            # Check for each row of the dataframe and update the dictionary\n",
    "            score = df[col][n]\n",
    "            if df_target[col][n] == 1:           # Check if positive\n",
    "                dic[score] = [dic[score][0]+1, dic[score][1]] # Increment positive instances\n",
    "            else:                                # Negative\n",
    "                dic[score] = [dic[score][0], dic[score][1]+1] # Increment negative instances\n",
    "\n",
    "        dic_sorted = {}\n",
    "        sorted_list = np.array([dic[key] for key in sorted(dic, reverse=True)]) # Create a reversely sorted list of positive and negative instances\n",
    "        \n",
    "        tp = sorted_list[:,0] # Get true positives from the list\n",
    "        fp = sorted_list[:,1] # Get false positives from the list\n",
    "\n",
    "        AUC_tmp = 0 # Initialize AUC\n",
    "        cov_tp = 0 # Initialize cov_tp\n",
    "        tot_tp = sum(tp) # Get total number of TP\n",
    "        tot_fp = sum(fp) # Get total number of FP\n",
    "        for i in range(len(tp)):\n",
    "            if fp[i] == 0:\n",
    "                cov_tp += tp[i]\n",
    "            elif tp[i] == 0:\n",
    "                AUC_tmp += (cov_tp/tot_tp)*(fp[i]/tot_fp) # Update AUC_tmp\n",
    "            else:\n",
    "                AUC_tmp += (cov_tp/tot_tp)*(fp[i]/tot_fp)+(tp[i]/tot_tp)*(fp[i]/tot_fp)/2 # Update AUC_tmp\n",
    "                cov_tp += tp[i]\n",
    "\n",
    "        #print('AUC_tmp: '+str(AUC_tmp))\n",
    "        AUC += sum(df_target[col])/len(df_target)*AUC_tmp # Add weighted AUC_tmp to AUC \n",
    "    return AUC\n",
    "# End of AUC function -----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define the class DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class DecisionTree with three functions __init__, fit and predict (after the comments):\n",
    "#\n",
    "# Input to __init__: \n",
    "# self: the object itself\n",
    "#\n",
    "# Output from __init__:\n",
    "# nothing\n",
    "# \n",
    "# This function does not return anything but just initializes the following attributes of the object (self) to None:\n",
    "# binning, imputatiom, labels, model\n",
    "#\n",
    "# Input to fit:\n",
    "# self: the object itself\n",
    "# df: a dataframe (where the column names \"CLASS\" and \"ID\" have special meaning)\n",
    "# nobins: no. of bins (default = 10)\n",
    "# bintype: either \"equal-width\" (default) or \"equal-size\"\n",
    "# min_samples_split: no. of instances required to allow a split (default = 5)\n",
    "#\n",
    "# Output from fit:\n",
    "# nothing\n",
    "#\n",
    "# The result of applying this function should be:\n",
    "#\n",
    "# self.binning should be a discretization mapping (see Assignment 1) from df\n",
    "# self.imputation should be an imputation mapping (see Assignment 1) from df\n",
    "# self.labels should be the categories of the \"CLASS\" column of df, set to be of type \"category\" \n",
    "# self.model should be a decision tree (for details, see lecture slides), where the leafs return class probabilities\n",
    "# Note that the function does not return anything but just assigns values to the attributes of the object.\n",
    "#\n",
    "# Hint 1: First find the available features (excluding \"CLASS\" and \"ID\"), then find the class counts, e.g., using \n",
    "#         groupby, and calculate the default class probabilities (relative frequencies of the class labels)\n",
    "# Hint 2: Define a function, e.g., called divide_and_conquer, that takes the above as input together with df \n",
    "#         and min_samples_split, and also a nodeno (starting with 0) to keep track of the generated nodes in the tree\n",
    "# Hint 3: You may represent the tree under construction as a list of nodes (tuples), on the form:\n",
    "#         (nodeno,\"leaf\",class_probabilities): corresponding to a leaf node where class_probabilities is a vector\n",
    "#                                              with the relative class frequencies (ordered according to self.labels)\n",
    "#         (nodeno,feature,node_dict): corresponding to an internal (non-leaf) node where node_dict is a mapping from\n",
    "#                                     the possible values of feature to child nodes (their nodenos)\n",
    "# Hint 4: You may evaluate each feature by a function information_content, which takes the group sizes\n",
    "#         for each possible value of the feature together with the class counts of each group as input\n",
    "# Hint 5: The best feature found (with lowest resulting information content) will be used to split the training\n",
    "#         instances, and each sub-group is used for generating a sub-tree (recursively by divide_and_conquer,\n",
    "#         see lecture slides for details)\n",
    "# Hint 6: You may make divide_and_conquer return not only a list of nodes, but also a current_node_no; \n",
    "#         by this, each subsequent call to divide_and_conquer for each subset of instances, i.e. for each feature value, \n",
    "#         could use current_node_no as a starting point.\n",
    "#         If you e.g. make the following call:\n",
    "#\n",
    "#         current_node_no, node_list = divide_and_conquer(current_node_no, ...)\n",
    "#\n",
    "#         then the returned value in current_node_no can be used in the next call to divide_and_conquer.\n",
    "#         Node that node_list will contain an arbitrary number of tuples, each element corresponding to a node together \n",
    "#         with a node number. The first element in the list will have the same number as current_node_no when the call \n",
    "#         was made and the last element will have a number one less than current_node_no when returned, e.g., if there is\n",
    "#         only one (leaf) node in the returned list, then current_node_no will only be incremented by one through the above call.\n",
    "# Hint 7: The list of nodes output by divide_and_conquer may finally be converted to an array, where each nodeno in the \n",
    "#         tuples corresponds to an index of the array \n",
    "#\n",
    "# Input to predict:\n",
    "# self: the object itself\n",
    "# df: a dataframe\n",
    "# \n",
    "# Output from predict:\n",
    "# predictions: a dataframe with class labels as column names and the rows corresponding to\n",
    "#              predictions with estimated class probabilities for each row in df, where the class probabilities\n",
    "#              are the relative class frequencies in the leaves of the decision tree into which the instances in\n",
    "#              df fall\n",
    "#\n",
    "# Hint 1: Drop any \"CLASS\" and \"ID\" columns first and then apply imputation and binning\n",
    "# Hint 2: Iterate over the rows calling some sub-function, e.g., make_prediction(nodeno,row), which for a test row\n",
    "#         finds a leaf node from which class probabilities are obtained\n",
    "# Hint 3: This sub-function may recursively traverse the tree (represented by an array), starting with the nodeno\n",
    "#         that corresponds to the root\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT TOUCH!\n",
    "class DecisionTree:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.binning = None\n",
    "        self.imputation = None\n",
    "        self.labels = None\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, df, nobins=10, bintype=\"equal-width\", min_samples_split=5): # Where min_samples_split is no. of instances required to allow a split\n",
    "        df_tmp,self.imputation = create_imputation(df) # Imputation mapping from df_tmp TODO check if it is from df or df_tmp\n",
    "        df_tmp,self.binning = create_bins(df_tmp, nobins, bintype) # Discretization mapping from df\n",
    "        self.labels = np.sort(df[\"CLASS\"].astype(\"category\").unique()) # Categories of the \"CLASS\" column of df, set to be of type \"category\" \n",
    "        \n",
    "        \n",
    "        # 2. Define a function, e.g., called divide_and_conquer, that takes the above as input together with df \n",
    "        #    and min_samples_split, and also a nodeno (starting with 0) to keep track of the generated nodes in the tree\n",
    "        def divide_and_conquer(df, features, class_counts, default_class_probabilities, min_samples_split, nodeno):  \n",
    "            #print(node_list)\n",
    "            if len(df) >= min_samples_split:\n",
    "                if len(df[\"CLASS\"].unique()) > 1:\n",
    "                    if len(features) > 0:\n",
    "                        # Get a mapping from the features to the group sizes for each possible value of the features\n",
    "                        group_sizes = group_sizes_per_feature(df)\n",
    "                        #print(group_sizes)\n",
    "                        \n",
    "                        # Evaluate each feature by a function information_content, which takes the group sizes\n",
    "                        # for each possible value of the feature together with the class counts of each group as input\n",
    "                        residual_information_features_values = information_content(group_sizes,class_counts,features)\n",
    "                        \n",
    "                        # Find the best question to split the dataframe (the one with the lowest residual information)\n",
    "                        feature,value = find_best_question(residual_information_features_values)\n",
    "                        #print(feature)\n",
    "                        \n",
    "                        # According to the \"question\" above (feature + value) split the dataframe\n",
    "                        lower_equal_df, greater_df = split(df,feature,value)\n",
    "                        #print(len(lower_equal_df))\n",
    "                        #print(greater_df)\n",
    "                        \n",
    "                        if nodeno == 0:\n",
    "                            lower_equal_child_nodeno = 1\n",
    "                            greater_child_nodeno = 2\n",
    "\n",
    "                        else:\n",
    "                            lower_equal_child_nodeno = greater_child_nodes[-1] + 1\n",
    "                            greater_child_nodeno = lower_equal_child_nodeno + 1\n",
    "                        \n",
    "                        greater_child_nodes.append(greater_child_nodeno)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        # Append a new non-leaf node\n",
    "                        node_dict = {\"<=\"+str(value):lower_equal_child_nodeno,\">\"+str(value):greater_child_nodeno} # node_dict is a mapping from the possible values of feature to child nodes (their nodenos)\n",
    "                        \n",
    "                        node_list.append((nodeno,feature,node_dict)) \n",
    "                        #print(node_list)\n",
    "                        \n",
    "                        features = features.drop(feature) # Get remaining features after last split\n",
    "                        \n",
    "                        # Lower or equal divide and conquer input parameters\n",
    "                        class_counts_LE = lower_equal_df.groupby(\"CLASS\").size() # Find the class counts\n",
    "\n",
    "                        \n",
    "                        # Greater input parameters\n",
    "                        class_counts_G = greater_df.groupby(\"CLASS\").size() # Find the class counts\n",
    "\n",
    "\n",
    "                        current_node_no, le_tree = divide_and_conquer(lower_equal_df, features, class_counts_LE, default_class_probabilities, min_samples_split,lower_equal_child_nodeno)\n",
    "                        #print(node_list)\n",
    "                        \n",
    "                        current_node_no, g_tree = divide_and_conquer(greater_df, features, class_counts_G, default_class_probabilities, min_samples_split,greater_child_nodeno)\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        # No more features left\n",
    "                        majority_class = df.groupby(\"CLASS\").size().idxmax()\n",
    "                        class_probabilities = [1. if majority_class == label else 0. for label in self.labels]\n",
    "                        #print(\"case3: {0}\".format(class_probabilities))\n",
    "                        return nodeno, node_list.append((nodeno,\"leaf\",class_probabilities)) # TODO REVIEW\n",
    "                else:\n",
    "                    unique_class = df[\"CLASS\"].unique()\n",
    "                    class_probabilities = [1. if unique_class == label else 0. for label in self.labels]\n",
    "                    #print(\"case2: {0}\".format(class_probabilities))\n",
    "                    return nodeno, node_list.append((nodeno,\"leaf\",class_probabilities)) # TODO REVIEW\n",
    "            else:\n",
    "                if df.empty:\n",
    "                    return nodeno, node_list.append((nodeno,\"leaf\",default_class_probabilities)) # TODO REVIEW\n",
    "                else:\n",
    "                    class_probabilities = [class_counts.get(label,0)/class_counts.sum() for label in self.labels]\n",
    "                    return nodeno, node_list.append((nodeno,\"leaf\",class_probabilities)) # TODO REVIEW\n",
    "                # Number of left instances < min_samples_split (default label)\n",
    "                #print(\"case1: {0}\".format(default_class_probabilities))\n",
    "               \n",
    "            #print(\"case0\")\n",
    "            return nodeno, node_list\n",
    "        \n",
    "        features = df_tmp.columns.drop([\"CLASS\",\"ID\"]) # Find the available features\n",
    "        class_counts = df_tmp.groupby(\"CLASS\").size() # Find the class counts\n",
    "        default_class_probabilities = [class_counts.get(label,0)/class_counts.sum() for label in self.labels]# Calculate the default class probabilities\n",
    "        \n",
    "        node_list = []\n",
    "        greater_child_nodes = []\n",
    "        nodeno,tree = divide_and_conquer(df_tmp, features, class_counts, default_class_probabilities, min_samples_split, 0)\n",
    "        \n",
    "        self.model = sorted(tree, key=lambda x: x[0])\n",
    "\n",
    "    def predict(self, df):\n",
    "        \n",
    "        # Hint 1: Drop any \"CLASS\" and \"ID\" columns first and then apply imputation and binning\n",
    "        df_tmp = df.drop(columns=[\"CLASS\",\"ID\"])\n",
    "        df_tmp = apply_imputation(df_tmp, self.imputation)\n",
    "        df_tmp = apply_bins(df_tmp,self.binning)\n",
    "        \n",
    "        # Hint 2: Iterate over the rows calling some sub-function, e.g., make_prediction(nodeno,row), which for a test row\n",
    "        #         finds a leaf node from which class probabilities are obtained\n",
    "        # Hint 3: This sub-function may recursively traverse the tree (represented by an array), starting with the nodeno\n",
    "        #         that corresponds to the root\n",
    "        def make_prediction(nodeno,row):\n",
    "            #print(\"Nodeno:{0} tree:{1} tree[nodeno][2]:{2}\".format(nodeno,tree[nodeno],tree[nodeno][2]))\n",
    "            if tree[nodeno][1] != \"leaf\":\n",
    "                feature = tree[nodeno][1]\n",
    "                for question in tree[nodeno][2].keys():\n",
    "                    #print(question)\n",
    "                    if eval(str(row[feature])+question):\n",
    "                        new_nodeno = tree[nodeno][2][question]\n",
    "                        \n",
    "                        return make_prediction(new_nodeno,row)\n",
    "            else: \n",
    "                return tree[nodeno][2]       \n",
    "                \n",
    "                \n",
    "            \n",
    "        \n",
    "        tree = self.model\n",
    "        #print(tree)\n",
    "        predictions = pd.DataFrame(0,index=np.arange(len(df_tmp)), columns=self.labels).fillna(0)\n",
    "        for index, row in df_tmp.iterrows():\n",
    "            prediction = make_prediction(0,row)\n",
    "            #print(prediction)\n",
    "            predictions.loc[index] = prediction\n",
    "        \n",
    "        #print(predictions)\n",
    "        return predictions\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING WITH THIS CELL \n",
    "class DecisionTree:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.binning = None\n",
    "        self.imputation = None\n",
    "        self.labels = None\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, df, nobins=10, bintype=\"equal-width\", min_samples_split=5): # Where min_samples_split is no. of instances required to allow a split\n",
    "        df_tmp,self.imputation = create_imputation(df) # Imputation mapping from df_tmp TODO check if it is from df or df_tmp\n",
    "        df_tmp,self.binning = create_bins(df_tmp, nobins, bintype) # Discretization mapping from df\n",
    "        self.labels = df[\"CLASS\"].astype(\"category\").cat.categories # Categories of the \"CLASS\" column of df, set to be of type \"category\" \n",
    "        \n",
    "        def majority_class_prob(df):\n",
    "            majority_class = df.groupby(\"CLASS\").size().idxmax()\n",
    "            class_probabilities = [1. if majority_class == label else 0. for label in self.labels]\n",
    "            return class_probabilities\n",
    "        \n",
    "        # 2. Define a function, e.g., called divide_and_conquer, that takes the above as input together with df \n",
    "        #    and min_samples_split, and also a nodeno (starting with 0) to keep track of the generated nodes in the tree\n",
    "        def divide_and_conquer(df, features, class_counts, default_class_probabilities, min_samples_split, nodeno):  \n",
    "            #print(node_list)\n",
    "            if len(df) >= min_samples_split:\n",
    "                if len(df[\"CLASS\"].unique()) > 1:\n",
    "                    if len(features) > 0:\n",
    "                        # Get a mapping from the features to the group sizes for each possible value of the features\n",
    "                        group_sizes = group_sizes_per_feature(df)\n",
    "                        #print(group_sizes)\n",
    "                        \n",
    "                        # Evaluate each feature by a function information_content, which takes the group sizes\n",
    "                        # for each possible value of the feature together with the class counts of each group as input\n",
    "                        residual_information_features_values = information_content(group_sizes,class_counts,features)\n",
    "                        \n",
    "                        # Find the best question to split the dataframe (the one with the lowest residual information)\n",
    "                        feature,value = find_best_question(residual_information_features_values)\n",
    "                        #print(feature)\n",
    "                        \n",
    "                        # According to the \"question\" above (feature + value) split the dataframe\n",
    "                        lower_equal_df, greater_df = split(df,feature,value)\n",
    "                        #print(len(lower_equal_df))\n",
    "                        #print(greater_df)\n",
    "                        \n",
    "                        if nodeno == 0:\n",
    "                            lower_equal_child_nodeno = 1\n",
    "                            greater_child_nodeno = 2\n",
    "\n",
    "                        else:\n",
    "                            lower_equal_child_nodeno = greater_child_nodes[-1] + 1\n",
    "                            greater_child_nodeno = lower_equal_child_nodeno + 1\n",
    "                        \n",
    "                        greater_child_nodes.append(greater_child_nodeno)\n",
    "                        \n",
    "                        # Append a new non-leaf node\n",
    "                        node_dict = {\"<=\"+str(value):lower_equal_child_nodeno,\">\"+str(value):greater_child_nodeno} # node_dict is a mapping from the possible values of feature to child nodes (their nodenos)\n",
    "                        \n",
    "                        node_list.append((nodeno,feature,node_dict)) \n",
    "                        #print(node_list)\n",
    "                        \n",
    "                        features = features.drop(feature) # Get remaining features after last split\n",
    "                        \n",
    "                        # Lower or equal divide and conquer input parameters\n",
    "                        class_counts_LE = lower_equal_df.groupby(\"CLASS\").size() # Find the class counts\n",
    "                        if len(lower_equal_df) >= 1 and len(np.unique(class_counts_LE.values)) != 1:\n",
    "                            #default_class_probabilities_LE =  majority_class_prob(lower_equal_df)\n",
    "                            default_class_probabilities_LE = [class_counts_LE.get(label,0)/class_counts_LE.sum() for label in self.labels]\n",
    "                        else:\n",
    "                            default_class_probabilities_LE = default_class_probabilities\n",
    "                            \n",
    "                        \n",
    "                        # Greater input parameters\n",
    "                        class_counts_G = greater_df.groupby(\"CLASS\").size() # Find the class counts\n",
    "                        if len(greater_df) >= 1 and len(np.unique(class_counts_G.values)) != 1:\n",
    "                            #default_class_probabilities_G =  majority_class_prob(greater_df)\n",
    "                            default_class_probabilities_G = [class_counts_G.get(label,0)/class_counts_G.sum() for label in self.labels]\n",
    "                        else:\n",
    "                            default_class_probabilities_G = default_class_probabilities\n",
    "                            \n",
    "                        divide_and_conquer(lower_equal_df, features, class_counts_LE, default_class_probabilities_LE, min_samples_split, lower_equal_child_nodeno)\n",
    "                        divide_and_conquer(greater_df, features, class_counts_G, default_class_probabilities_G, min_samples_split, greater_child_nodeno)\n",
    "\n",
    "                    else:\n",
    "                        # No more features left\n",
    "                        #class_probabilities = majority_class_prob(df)\n",
    "                        class_probabilities = [class_counts.get(label,0)/class_counts.sum() for label in self.labels]\n",
    "                        #print(\"case3: {0}\".format(class_probabilities))\n",
    "                        return nodeno, node_list.append((nodeno,\"leaf\",class_probabilities)) # TODO REVIEW\n",
    "                else:\n",
    "                    #unique_class = df[\"CLASS\"].unique()\n",
    "                    #class_probabilities = [1. if unique_class == label else 0. for label in self.labels]\n",
    "                    class_probabilities = [class_counts.get(label,0)/class_counts.sum() for label in self.labels]\n",
    "                    #print(\"case2: {0}\".format(class_probabilities))\n",
    "                    return nodeno, node_list.append((nodeno,\"leaf\",class_probabilities)) # TODO REVIEW\n",
    "            else:\n",
    "                #return nodeno, node_list.append((nodeno,\"leaf\",default_class_probabilities)) # TODO REVIEW\n",
    "                if df.empty or len(np.unique(class_counts.values)) == 1:\n",
    "                    #print(\"case1: {0}\".format(default_class_probabilities))\n",
    "                    return nodeno, node_list.append((nodeno,\"leaf\",default_class_probabilities)) # TODO REVIEW\n",
    "                else:\n",
    "                    class_probabilities = [class_counts.get(label,0)/class_counts.sum() for label in self.labels]\n",
    "                    #class_probabilities = majority_class_prob(df)\n",
    "                    return nodeno, node_list.append((nodeno,\"leaf\",class_probabilities)) # TODO REVIEW\n",
    "                # Number of left instances < min_samples_split (default label)\n",
    "                #print(\"case1: {0}\".format(default_class_probabilities))\n",
    "               \n",
    "            #print(\"case0\")\n",
    "            return nodeno, node_list\n",
    "        \n",
    "        features = df_tmp.columns.drop([\"CLASS\",\"ID\"]) # Find the available features\n",
    "        class_counts = df_tmp.groupby(\"CLASS\").size() # Find the class counts\n",
    "        default_class_probabilities = [class_counts.get(label,0)/class_counts.sum() for label in self.labels]# Calculate the default class probabilities\n",
    "        \n",
    "        node_list = []\n",
    "        greater_child_nodes = []\n",
    "        nodeno,tree = divide_and_conquer(df_tmp, features, class_counts, default_class_probabilities, min_samples_split, 0)\n",
    "        \n",
    "        self.model = sorted(tree, key=lambda x: x[0])\n",
    "\n",
    "    def predict(self, df):\n",
    "        \n",
    "        # Hint 1: Drop any \"CLASS\" and \"ID\" columns first and then apply imputation and binning\n",
    "        df_tmp = df.drop(columns=[\"CLASS\",\"ID\"])\n",
    "        df_tmp = apply_imputation(df_tmp, self.imputation)\n",
    "        df_tmp = apply_bins(df_tmp,self.binning)\n",
    "        \n",
    "        # Hint 2: Iterate over the rows calling some sub-function, e.g., make_prediction(nodeno,row), which for a test row\n",
    "        #         finds a leaf node from which class probabilities are obtained\n",
    "        # Hint 3: This sub-function may recursively traverse the tree (represented by an array), starting with the nodeno\n",
    "        #         that corresponds to the root\n",
    "        def make_prediction(nodeno,row):\n",
    "            #print(\"Nodeno:{0} tree:{1} tree[nodeno][2]:{2}\".format(nodeno,tree[nodeno],tree[nodeno][2]))\n",
    "            if tree[nodeno][1] != \"leaf\":\n",
    "                feature = tree[nodeno][1]\n",
    "                for question in tree[nodeno][2].keys():\n",
    "                    #print(question)\n",
    "                    if eval(str(row[feature])+question):\n",
    "                        new_nodeno = tree[nodeno][2][question]\n",
    "                        \n",
    "                        return make_prediction(new_nodeno,row)\n",
    "            else: \n",
    "                return tree[nodeno][2]       \n",
    "                \n",
    "                \n",
    "            \n",
    "        \n",
    "        tree = self.model\n",
    "        #print(tree)\n",
    "        predictions = pd.DataFrame(0,index=np.arange(len(df_tmp)), columns=self.labels).fillna(0)\n",
    "        for index, row in df_tmp.iterrows():\n",
    "            prediction = make_prediction(0,row)\n",
    "            #print(prediction)\n",
    "            predictions.loc[index] = prediction\n",
    "        \n",
    "        #print(predictions)\n",
    "        return predictions\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'group_sizes_per_feature' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7612a9037baa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mdefault_class_probabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m# Calculate the default class probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#print(default_class_probabilities) #OK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mgroup_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_sizes_per_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_tmp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#OK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;31m#print(group_sizes) #OK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'group_sizes_per_feature' is not defined"
     ]
    }
   ],
   "source": [
    "glass_train_df = pd.read_csv(\"glass_train.txt\")\n",
    "df = glass_train_df.copy()\n",
    "#df = df[[\"RI\",\"Na\",\"ID\",\"CLASS\"]][0:10]\n",
    "df = df[0:100]\n",
    "#print(df)\n",
    "nobins = 10\n",
    "bintype = \"equal-width\"\n",
    "df_tmp,imputation = create_imputation(df) # Imputation mapping from df_tmp TODO check if it is from df or df_tmp\n",
    "df_tmp,binning = create_bins(df_tmp, nobins, bintype) # Discretization mapping from df\n",
    "labels = df[\"CLASS\"].astype(\"category\").cat.categories # Categories of the \"CLASS\" column of df, set to be of type \"category\" \n",
    "#print(df_tmp)\n",
    "#print(\"\")\n",
    "\n",
    "#df_tmp = df_tmp.loc[1:2]\n",
    "#print(df_tmp)\n",
    "\n",
    "features = df_tmp.columns.drop([\"CLASS\",\"ID\"]) # Find the available features\n",
    "class_counts = df_tmp.groupby(\"CLASS\").size() # Find the class counts\n",
    "default_class_probabilities = [class_counts.get(label,0)/class_counts.sum() for label in labels]# Calculate the default class probabilities\n",
    "#print(default_class_probabilities) #OK\n",
    "group_sizes = group_sizes_per_feature(df_tmp) #OK\n",
    "#print(group_sizes) #OK\n",
    "\n",
    "residual_information_features_values = information_content(group_sizes,class_counts,features) #OK\n",
    "#print(residual_information_features_values) #OK\n",
    "\n",
    "feature,value = find_best_question(residual_information_features_values) #OK\n",
    "#print(\"Best question: Feature={0} Value={1}\".format(feature,value)) #OK\n",
    "#print(\"\")\n",
    "\n",
    "#lower_equal_df, greater_df = split(df_tmp,feature,value) #OK\n",
    "#print(\"Lower or equal Data Frame:\") \n",
    "#print(lower_equal_df) #OK\n",
    "#print(\"\")\n",
    "#print(\"Greater Data Frame:\")\n",
    "#print(greater_df) #OK\n",
    "\n",
    "#features = features.drop(feature) #OK\n",
    "#print(features) #OK\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def majority_class_prob(df):\n",
    "    majority_class = df.groupby(\"CLASS\").size().idxmax()\n",
    "    \n",
    "    class_probabilities = [1. if majority_class == label else 0. for label in labels]\n",
    "    return class_probabilities\n",
    "\n",
    "def divide_and_conquer(df, features, class_counts, default_class_probabilities, min_samples_split, nodeno):  \n",
    "    #print(node_list)\n",
    "    if len(df) >= min_samples_split:\n",
    "        if len(df[\"CLASS\"].unique()) > 1:\n",
    "            if len(features) > 0:\n",
    "                # Get a mapping from the features to the group sizes for each possible value of the features\n",
    "                group_sizes = group_sizes_per_feature(df)\n",
    "                #print(group_sizes)\n",
    "                        \n",
    "                # Evaluate each feature by a function information_content, which takes the group sizes\n",
    "                # for each possible value of the feature together with the class counts of each group as input\n",
    "                residual_information_features_values = information_content(group_sizes,class_counts,features)\n",
    "                        \n",
    "                # Find the best question to split the dataframe (the one with the lowest residual information)\n",
    "                feature,value = find_best_question(residual_information_features_values)\n",
    "                #print(feature)\n",
    "                        \n",
    "                # According to the \"question\" above (feature + value) split the dataframe\n",
    "                lower_equal_df, greater_df = split(df,feature,value)\n",
    "                #print(len(lower_equal_df))\n",
    "                #print(greater_df)\n",
    "                        \n",
    "                if nodeno == 0:\n",
    "                    lower_equal_child_nodeno = 1\n",
    "                    greater_child_nodeno = 2\n",
    "\n",
    "                else:\n",
    "                    lower_equal_child_nodeno = greater_child_nodes[-1] + 1\n",
    "                    greater_child_nodeno = lower_equal_child_nodeno + 1\n",
    "                        \n",
    "                greater_child_nodes.append(greater_child_nodeno)\n",
    "                        \n",
    "                # Append a new non-leaf node\n",
    "                node_dict = {\"<=\"+str(value):lower_equal_child_nodeno,\">\"+str(value):greater_child_nodeno} # node_dict is a mapping from the possible values of feature to child nodes (their nodenos)\n",
    "                        \n",
    "                node_list.append((nodeno,feature,node_dict)) \n",
    "                #print(node_list)\n",
    "                        \n",
    "                features = features.drop(feature) # Get remaining features after last split\n",
    "                        \n",
    "                # Lower or equal divide and conquer input parameters\n",
    "                class_counts_LE = lower_equal_df.groupby(\"CLASS\").size() # Find the class counts\n",
    "                if len(lower_equal_df) >= 1:\n",
    "                    default_class_probabilities_LE = [class_counts_LE.get(label,0)/class_counts_LE.sum() for label in labels]\n",
    "                    #default_class_probabilities_LE =  majority_class_prob(lower_equal_df)\n",
    "                else:\n",
    "                    default_class_probabilities_LE = default_class_probabilities\n",
    "                            \n",
    "                        \n",
    "                # Greater input parameters\n",
    "                class_counts_G = greater_df.groupby(\"CLASS\").size() # Find the class counts\n",
    "                if len(greater_df) >= 1:\n",
    "                    default_class_probabilities_G = [class_counts_G.get(label,0)/class_counts_G.sum() for label in labels]\n",
    "                    #default_class_probabilities_G =  majority_class_prob(greater_df)\n",
    "                else:\n",
    "                    default_class_probabilities_G = default_class_probabilities\n",
    "                            \n",
    "                divide_and_conquer(lower_equal_df, features, class_counts_LE, default_class_probabilities_LE, min_samples_split, lower_equal_child_nodeno)\n",
    "                divide_and_conquer(greater_df, features, class_counts_G, default_class_probabilities_G, min_samples_split, greater_child_nodeno)\n",
    "\n",
    "            else:\n",
    "                # No more features left\n",
    "                #class_probabilities = majority_class_prob(df)\n",
    "                class_probabilities = [class_counts.get(label,0)/class_counts.sum() for label in labels]\n",
    "                #print(df)\n",
    "                #print(\"case3: {0}\".format(class_probabilities))\n",
    "                return nodeno, node_list.append((nodeno,\"leaf\",class_probabilities)) # TODO REVIEW\n",
    "        else:\n",
    "            unique_class = df[\"CLASS\"].unique()\n",
    "            class_probabilities = [class_counts.get(label,0)/class_counts.sum() for label in labels]\n",
    "            #class_probabilities = [1. if unique_class == label else 0. for label in labels]\n",
    "            #print(df)\n",
    "            #print(\"case2: {0}\".format(class_probabilities))\n",
    "            return nodeno, node_list.append((nodeno,\"leaf\",class_probabilities)) # TODO REVIEW\n",
    "    else:\n",
    "        #return nodeno, node_list.append((nodeno,\"leaf\",default_class_probabilities)) # TODO REVIEW\n",
    "        if df.empty:\n",
    "            #print(\"case1: {0}\".format(default_class_probabilities))\n",
    "            return nodeno, node_list.append((nodeno,\"leaf\",default_class_probabilities)) # TODO REVIEW\n",
    "        else:\n",
    "            class_probabilities = [class_counts.get(label,0)/class_counts.sum() for label in labels]\n",
    "            #class_probabilities = majority_class_prob(df)\n",
    "            return nodeno, node_list.append((nodeno,\"leaf\",class_probabilities)) # TODO REVIEW\n",
    "        # Number of left instances < min_samples_split (default label)\n",
    "        #print(\"case1: {0}\".format(default_class_probabilities))\n",
    "               \n",
    "    #print(\"case0\")\n",
    "    return nodeno, node_list\n",
    "\n",
    "node_list = []\n",
    "greater_child_nodes = []\n",
    "min_samples_split = 1\n",
    "nodeno,tree = divide_and_conquer(df_tmp, features, class_counts, default_class_probabilities, min_samples_split, 0)\n",
    "tree = sorted(tree, key=lambda x: x[0])\n",
    "print(tree)\n",
    "\n",
    "\n",
    "\n",
    "#print(df_tmp)\n",
    "# Hint 1: Drop any \"CLASS\" and \"ID\" columns first and then apply imputation and binning\n",
    "df_tmp2 = df_tmp.drop(columns=[\"CLASS\",\"ID\"])\n",
    "        \n",
    "# Hint 2: Iterate over the rows calling some sub-function, e.g., make_prediction(nodeno,row), which for a test row\n",
    "#         finds a leaf node from which class probabilities are obtained\n",
    "# Hint 3: This sub-function may recursively traverse the tree (represented by an array), starting with the nodeno\n",
    "#         that corresponds to the root\n",
    "def make_prediction(nodeno,row):\n",
    "    #print(\"Nodeno:{0} tree:{1} tree[nodeno][2]:{2}\".format(nodeno,tree[nodeno],tree[nodeno][2]))\n",
    "    if tree[nodeno][1] != \"leaf\":\n",
    "        feature = tree[nodeno][1]\n",
    "        for question in tree[nodeno][2].keys():\n",
    "            #print(question)\n",
    "            if eval(str(row[feature])+question):\n",
    "                new_nodeno = tree[nodeno][2][question]\n",
    "                #print(\"Row:{4}={0} Nodeno:{1} Question:{2} Newnodeno:{3}\".format(row[feature],nodeno, question, new_nodeno,feature))\n",
    "                        \n",
    "                return make_prediction(new_nodeno,row)\n",
    "    else: \n",
    "        return tree[nodeno][2]       \n",
    "                \n",
    "                \n",
    "train_labels = df_tmp[\"CLASS\"]           \n",
    "#print(tree)\n",
    "predictions = pd.DataFrame(0,index=np.arange(len(df_tmp2)), columns=labels).fillna(0)\n",
    "for index, row in df_tmp2.iterrows():\n",
    "    prediction = make_prediction(0,row)\n",
    "    #print(prediction)\n",
    "    predictions.loc[index] = prediction\n",
    "    #print(predictions)\n",
    "    \n",
    "print(accuracy(predictions,train_labels))\n",
    "#print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes a dataframe and returns a mapping from the features to \n",
    "# the group sizes for each possible value of the feature\n",
    "def group_sizes_per_feature(df):\n",
    "    output = dict.fromkeys(df.columns.drop([\"CLASS\",\"ID\"]), {})                                  # Initialize dictionary from features\n",
    "    for col in df.columns.drop([\"CLASS\",\"ID\"]):                                                  # For each column excluding \"CLASS\" and \"ID\"\n",
    "        output[col] = {}                                                                         # Necessary to Assign Nested Keys and Values in Dictionaries (https://stackoverflow.com/questions/22455384/assign-nested-keys-and-values-in-dictionaries)\n",
    "        for value in df[col].unique():                                                           # For each value of the column\n",
    "            lower_equal_cases_series = df[df[col] <= value].groupby(\"CLASS\").size()      # Find those instances that are lower or equal than the value and group them by CLASS\n",
    "            greater_cases_series = df[df[col] > value].groupby(\"CLASS\").size()           # Find those instances that are greater than the value and group them by CLASS\n",
    "        \n",
    "            le = {label:lower_equal_cases_series.get(label,0) for label in df[\"CLASS\"].unique()} # TODO CHANGE CLASS FOR LABELS Transform lower_equal_cases_series to a structured dictionary where empty classes have a 0 as value\n",
    "            g = {label:greater_cases_series.get(label,0) for label in df[\"CLASS\"].unique()}      # TODO CHANGE CLASS FOR LABELS Transform greater_cases_series to a structured dictionary where empty classes have a 0 as value\n",
    "\n",
    "            output[col][value] = [le, g]                                                         # Update the output\n",
    "                        \n",
    "    return output\n",
    "\n",
    "def entropy(class_counts):\n",
    "# Computes entropy from class_counts\n",
    "    #print(class_counts)\n",
    "    non_zero_labels_count = sum(np.fromiter(class_counts.values(), dtype=int) >= 0)\n",
    "    if non_zero_labels_count <= 1:\n",
    "        return 0\n",
    "    \n",
    "    num_instances = sum(class_counts.values())\n",
    "    if num_instances <= 1:\n",
    "        return 0\n",
    "    \n",
    "    probs = list(class_counts.values())/sum(class_counts.values())\n",
    "    #probs = np.array(list(class_counts.values()))/sum(class_counts.values())\n",
    "    return sum([0 if i == 0 else -i * np.log2(i) for i in probs])\n",
    "\n",
    "def information_content(group_sizes,class_counts,features): # TODO: class_counts not used and features used ??!!\n",
    "    res_inf = dict.fromkeys(features, {})\n",
    "    for feature in group_sizes.keys():\n",
    "        res_inf[feature] = {}\n",
    "        for value in group_sizes[feature].keys():\n",
    "            dict_lower_equal = group_sizes.get(feature).get(value)[0]\n",
    "            dict_greater = group_sizes.get(feature).get(value)[1]\n",
    "\n",
    "            lower_equal_instances = sum(dict_lower_equal.values())\n",
    "            greater_instances = sum(dict_greater.values())\n",
    "            total_instances = lower_equal_instances + greater_instances # TODO: Check if sum(class_counts) == lower_equal_instances + greater_instances\n",
    "\n",
    "            lower_equal_entropy = entropy(dict_lower_equal)\n",
    "            greater_entropy = entropy(dict_greater)\n",
    "\n",
    "            res_inf[feature][value] = (lower_equal_instances/total_instances)*lower_equal_entropy + (greater_instances/total_instances)*greater_entropy\n",
    "    return res_inf\n",
    "\n",
    "def find_best_question(res_inf):\n",
    "    lowest_information = 20000\n",
    "    for feature in res_inf.keys():\n",
    "        for value in res_inf[feature].keys():\n",
    "            res_inf_value = res_inf[feature][value]\n",
    "            if res_inf_value < lowest_information:\n",
    "                lowest_information = res_inf_value\n",
    "                feature_out = feature\n",
    "                value_out = value\n",
    "    #print(\"Feature:{0} Value:{1} ResInf:{2}\".format(feature_out,value_out,lowest_information))            \n",
    "    return feature_out,value_out\n",
    "\n",
    "#SPLIT\n",
    "def split(df,feature,value):\n",
    "    lower_equal_cases = df[df[feature] <= value].drop(columns=feature)\n",
    "    greater_cases = df[df[feature] > value].drop(columns=feature)\n",
    "    return lower_equal_cases, greater_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (5, 'equal-width', 3): 1.80 s.\n",
      "Testing time (5, 'equal-width', 3): 0.11 s.\n",
      "Training time (5, 'equal-width', 5): 1.56 s.\n",
      "Testing time (5, 'equal-width', 5): 0.09 s.\n",
      "Training time (5, 'equal-width', 10): 1.18 s.\n",
      "Testing time (5, 'equal-width', 10): 0.08 s.\n",
      "Training time (5, 'equal-size', 3): 1.87 s.\n",
      "Testing time (5, 'equal-size', 3): 0.10 s.\n",
      "Training time (5, 'equal-size', 5): 1.55 s.\n",
      "Testing time (5, 'equal-size', 5): 0.09 s.\n",
      "Training time (5, 'equal-size', 10): 1.13 s.\n",
      "Testing time (5, 'equal-size', 10): 0.08 s.\n",
      "Training time (10, 'equal-width', 3): 2.07 s.\n",
      "Testing time (10, 'equal-width', 3): 0.09 s.\n",
      "Training time (10, 'equal-width', 5): 1.83 s.\n",
      "Testing time (10, 'equal-width', 5): 0.09 s.\n",
      "Training time (10, 'equal-width', 10): 1.41 s.\n",
      "Testing time (10, 'equal-width', 10): 0.08 s.\n",
      "Training time (10, 'equal-size', 3): 2.49 s.\n",
      "Testing time (10, 'equal-size', 3): 0.09 s.\n",
      "Training time (10, 'equal-size', 5): 2.28 s.\n",
      "Testing time (10, 'equal-size', 5): 0.09 s.\n",
      "Training time (10, 'equal-size', 10): 1.97 s.\n",
      "Testing time (10, 'equal-size', 10): 0.08 s.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Brier score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">equal-width</th>\n",
       "      <th>3</th>\n",
       "      <td>0.663551</td>\n",
       "      <td>0.495742</td>\n",
       "      <td>0.823196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.663551</td>\n",
       "      <td>0.513286</td>\n",
       "      <td>0.815376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.663551</td>\n",
       "      <td>0.509703</td>\n",
       "      <td>0.815924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">equal-size</th>\n",
       "      <th>3</th>\n",
       "      <td>0.570093</td>\n",
       "      <td>0.715156</td>\n",
       "      <td>0.747264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.570093</td>\n",
       "      <td>0.660114</td>\n",
       "      <td>0.760360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.532710</td>\n",
       "      <td>0.698032</td>\n",
       "      <td>0.740427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">10</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">equal-width</th>\n",
       "      <th>3</th>\n",
       "      <td>0.663551</td>\n",
       "      <td>0.536818</td>\n",
       "      <td>0.819388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.547826</td>\n",
       "      <td>0.819928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.626168</td>\n",
       "      <td>0.541446</td>\n",
       "      <td>0.810556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">equal-size</th>\n",
       "      <th>3</th>\n",
       "      <td>0.570093</td>\n",
       "      <td>0.722610</td>\n",
       "      <td>0.744371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.671468</td>\n",
       "      <td>0.754668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.654746</td>\n",
       "      <td>0.754630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Accuracy  Brier score       AUC\n",
       "5  equal-width 3   0.663551     0.495742  0.823196\n",
       "               5   0.663551     0.513286  0.815376\n",
       "               10  0.663551     0.509703  0.815924\n",
       "   equal-size  3   0.570093     0.715156  0.747264\n",
       "               5   0.570093     0.660114  0.760360\n",
       "               10  0.532710     0.698032  0.740427\n",
       "10 equal-width 3   0.663551     0.536818  0.819388\n",
       "               5   0.616822     0.547826  0.819928\n",
       "               10  0.626168     0.541446  0.810556\n",
       "   equal-size  3   0.570093     0.722610  0.744371\n",
       "               5   0.598131     0.671468  0.754668\n",
       "               10  0.598131     0.654746  0.754630"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your code (leave this part unchanged, except for if auc is undefined)\n",
    "\n",
    "glass_train_df = pd.read_csv(\"glass_train.txt\")\n",
    "\n",
    "glass_test_df = pd.read_csv(\"glass_test.txt\")\n",
    "\n",
    "tree_model = DecisionTree()\n",
    "\n",
    "test_labels = glass_test_df[\"CLASS\"]\n",
    "\n",
    "nobins_values = [5,10]\n",
    "bintype_values = [\"equal-width\",\"equal-size\"]\n",
    "min_samples_split_values = [3,5,10]\n",
    "parameters = [(nobins,bintype,min_samples_split) for nobins in nobins_values for bintype in bintype_values \n",
    "              for min_samples_split in min_samples_split_values]\n",
    "\n",
    "results = np.empty((len(parameters),3))\n",
    "\n",
    "for i in range(len(parameters)):\n",
    "    t0 = time.perf_counter()\n",
    "    tree_model.fit(glass_train_df,nobins=parameters[i][0],bintype=parameters[i][1],min_samples_split=parameters[i][2])\n",
    "    print(\"Training time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    t0 = time.perf_counter()\n",
    "    predictions = tree_model.predict(glass_test_df)\n",
    "    print(\"Testing time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    results[i] = [accuracy(predictions,test_labels),brier_score(predictions,test_labels),\n",
    "                  auc(predictions,test_labels)] # Assuming that you have defined auc - remove otherwise\n",
    "\n",
    "results = pd.DataFrame(results,index=pd.MultiIndex.from_product([nobins_values,bintype_values,min_samples_split_values]),\n",
    "                       columns=[\"Accuracy\",\"Brier score\",\"AUC\"])\n",
    "\n",
    "results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.91\n",
      "AUC on training set: 0.98\n",
      "Brier score on training set: 0.13\n"
     ]
    }
   ],
   "source": [
    "train_labels = glass_train_df[\"CLASS\"]\n",
    "tree_model.fit(glass_train_df,min_samples_split=1)\n",
    "predictions = tree_model.predict(glass_train_df)\n",
    "print(\"Accuracy on training set: {0:.2f}\".format(accuracy(predictions,train_labels)))\n",
    "print(\"AUC on training set: {0:.2f}\".format(auc(predictions,train_labels)))\n",
    "print(\"Brier score on training set: {0:.2f}\".format(brier_score(predictions,train_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment on assumptions, things that do not work properly, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the class DecisionForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class DecisionForest with three functions __init__, fit and predict (after the comments):\n",
    "#\n",
    "# Input to __init__: \n",
    "# self: the object itself\n",
    "#\n",
    "# Output from __init__:\n",
    "# nothing\n",
    "# \n",
    "# This function does not return anything but just initializes the following attributes of the object (self) to None:\n",
    "# binning, imputatiom, labels, model\n",
    "#\n",
    "# Input to fit:\n",
    "# self: the object itself\n",
    "# df: a dataframe (where the column names \"CLASS\" and \"ID\" have special meaning)\n",
    "# nobins: no. of bins (default = 10)\n",
    "# bintype: either \"equal-width\" (default) or \"equal-size\"\n",
    "# min_samples_split: no. of instances required to allow a split (default = 5)\n",
    "# random_features: no. of features to evaluate at each split (default = 2), 0 means all features (no random sampling)\n",
    "# notrees: no. of trees in the forest (default = 10)\n",
    "#\n",
    "# Output from fit:\n",
    "# nothing\n",
    "#\n",
    "# The result of applying this function should be:\n",
    "#\n",
    "# self.binning should be a discretization mapping (see Assignment 1) from df\n",
    "# self.imputation should be an imputation mapping (see Assignment 1) from df\n",
    "# self.labels should be the categories of the \"CLASS\" column of df, set to be of type \"category\" \n",
    "# self.model should be a random forest (for details, see lecture slides)\n",
    "# Note that the function does not return anything but just assigns values to the attributes of the object.\n",
    "#\n",
    "# Hint 1: Redefine divide_and_conquer to take one additional argument; random_features, and instead of\n",
    "#         evaluating all features choose a random subset, e.g., by np.random.choice (without replacement)\n",
    "# Hint 2: Generate each tree in the forest from a bootstrap replicate of df, e.g., by np.random.choice \n",
    "#         (with replacement) from the index values of df.\n",
    "#\n",
    "# Input to predict:\n",
    "# self: the object itself\n",
    "# df: a dataframe\n",
    "# \n",
    "# Output from predict:\n",
    "# predictions: a dataframe with class labels as column names and the rows corresponding to\n",
    "#              predictions with estimated class probabilities for each row in df, where the class probabilities\n",
    "#              are the mean of all relative class frequencies in the leaves of the forest into which the instances in\n",
    "#              df fall\n",
    "#\n",
    "# Hint 1: Drop any \"CLASS\" and \"ID\" columns first and then apply imputation and binning\n",
    "# Hint 2: Iterate over the rows calling some sub-function, e.g., make_prediction(row), which for a test row\n",
    "#         finds all leaf nodes and calculates the average of their class probabilities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionForest:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.binning = None\n",
    "        self.imputation = None\n",
    "        self.labels = None\n",
    "        self.model = None\n",
    "   \n",
    "    # Input to fit:\n",
    "    # self: the object itself\n",
    "    # df: a dataframe (where the column names \"CLASS\" and \"ID\" have special meaning)\n",
    "    # nobins: no. of bins (default = 10)\n",
    "    # bintype: either \"equal-width\" (default) or \"equal-size\"\n",
    "    # min_samples_split: no. of instances required to allow a split (default = 5)\n",
    "    # random_features: no. of features to evaluate at each split (default = 2), 0 means all features (no random sampling)\n",
    "    # notrees: no. of trees in the forest (default = 10)\n",
    "    def fit(self, df, nobins=10, bintype=\"equal-width\", min_samples_split=5, random_features=2, notrees=10):\n",
    "        # Note that the function does not return anything but just assigns values to the attributes of the object.\n",
    "        #\n",
    "        # Hint 1: Redefine divide_and_conquer to take one additional argument; random_features, and instead of\n",
    "        #         evaluating all features choose a random subset, e.g., by np.random.choice (without replacement)\n",
    "        # Hint 2: Generate each tree in the forest from a bootstrap replicate of df, e.g., by np.random.choice \n",
    "        #         (with replacement) from the index values of df.\n",
    "        df_tmp,self.imputation = create_imputation(df) # Imputation mapping from df_tmp TODO check if it is from df or df_tmp\n",
    "        df_tmp,self.binning = create_bins(df_tmp, nobins, bintype) # Discretization mapping from df\n",
    "        self.labels = df[\"CLASS\"].astype(\"category\").cat.categories # Categories of the \"CLASS\" column of df, set to be of type \"category\" \n",
    "        # self.model should be a random forest\n",
    "        \n",
    "        def divide_and_conquer(df, features, class_counts, default_class_probabilities, min_samples_split, random_features, nodeno):  \n",
    "            #print(node_list)\n",
    "            if len(df) >= min_samples_split:\n",
    "                if len(df[\"CLASS\"].unique()) > 1:\n",
    "                    if (len(features if random_features == 0 else remaining_features) > 0):\n",
    "                        #print(df)\n",
    "                        #print(remaining_features)\n",
    "                        #print(features)\n",
    "                        if random_features != 0:\n",
    "                            features = pd.Series(np.random.choice(remaining_features,random_features))\n",
    "                          \n",
    "                        # Get a mapping from the features to the group sizes for each possible value of the features\n",
    "                        group_sizes = group_sizes_per_feature_randforest(df,features)\n",
    "                        #print(group_sizes)\n",
    "                        \n",
    "                        # Evaluate each feature by a function information_content, which takes the group sizes\n",
    "                        # for each possible value of the feature together with the class counts of each group as input\n",
    "                        residual_information_features_values = information_content(group_sizes,class_counts,features)\n",
    "                        \n",
    "                        # Find the best question to split the dataframe (the one with the lowest residual information)\n",
    "                        feature,value = find_best_question(residual_information_features_values)\n",
    "                        \n",
    "                        # According to the \"question\" above (feature + value) split the dataframe\n",
    "                        lower_equal_df, greater_df = split(df,feature,value)\n",
    "                        #print(len(lower_equal_df))\n",
    "                        #print(greater_df)\n",
    "                        \n",
    "                        if nodeno == 0:\n",
    "                            lower_equal_child_nodeno = 1\n",
    "                            greater_child_nodeno = 2\n",
    "\n",
    "                        else:\n",
    "                            lower_equal_child_nodeno = greater_child_nodes[-1] + 1\n",
    "                            greater_child_nodeno = lower_equal_child_nodeno + 1\n",
    "                        \n",
    "                        greater_child_nodes.append(greater_child_nodeno)\n",
    "                        \n",
    "                        # Append a new non-leaf node\n",
    "                        node_dict = {\"<=\"+str(value):lower_equal_child_nodeno,\">\"+str(value):greater_child_nodeno} # node_dict is a mapping from the possible values of feature to child nodes (their nodenos)\n",
    "                        \n",
    "                        node_list.append((nodeno,feature,node_dict)) \n",
    "                        #print(node_list)\n",
    "                        \n",
    "                        if random_features != 0:\n",
    "                            remaining_features.remove(feature) # Update remaining features\n",
    "                        \n",
    "                        #features = features.drop(feature) # Get remaining features after last split\n",
    "                        \n",
    "                        # Lower or equal divide and conquer input parameters\n",
    "                        class_counts_LE = lower_equal_df.groupby(\"CLASS\").size() # Find the class counts\n",
    "                        if len(lower_equal_df) >= 1 and len(np.unique(class_counts_LE.values)) != 1:\n",
    "                            #default_class_probabilities_LE =  majority_class_prob(lower_equal_df)\n",
    "                            default_class_probabilities_LE = [class_counts_LE.get(label,0)/class_counts_LE.sum() for label in self.labels]\n",
    "                        else:\n",
    "                            default_class_probabilities_LE = default_class_probabilities\n",
    "                            \n",
    "                        \n",
    "                        # Greater input parameters\n",
    "                        class_counts_G = greater_df.groupby(\"CLASS\").size() # Find the class counts\n",
    "                        if len(greater_df) >= 1 and len(np.unique(class_counts_G.values)) != 1:\n",
    "                            #default_class_probabilities_G =  majority_class_prob(greater_df)\n",
    "                            default_class_probabilities_G = [class_counts_G.get(label,0)/class_counts_G.sum() for label in self.labels]\n",
    "                        else:\n",
    "                            default_class_probabilities_G = default_class_probabilities\n",
    "                            \n",
    "                        divide_and_conquer(lower_equal_df, features, class_counts_LE, default_class_probabilities_LE, min_samples_split, random_features, lower_equal_child_nodeno)\n",
    "                        divide_and_conquer(greater_df, features, class_counts_G, default_class_probabilities_G, min_samples_split, random_features, greater_child_nodeno)\n",
    "\n",
    "                    else:\n",
    "                        # No more features left\n",
    "                        #class_probabilities = majority_class_prob(df)\n",
    "                        class_probabilities = [class_counts.get(label,0)/class_counts.sum() for label in self.labels]\n",
    "                        #print(\"case3: {0}\".format(class_probabilities))\n",
    "                        return nodeno, node_list.append((nodeno,\"leaf\",class_probabilities)) # TODO REVIEW\n",
    "                else:\n",
    "                    #unique_class = df[\"CLASS\"].unique()\n",
    "                    #class_probabilities = [1. if unique_class == label else 0. for label in self.labels]\n",
    "                    class_probabilities = [class_counts.get(label,0)/class_counts.sum() for label in self.labels]\n",
    "                    #print(\"case2: {0}\".format(class_probabilities))\n",
    "                    return nodeno, node_list.append((nodeno,\"leaf\",class_probabilities)) # TODO REVIEW\n",
    "            else:\n",
    "                #return nodeno, node_list.append((nodeno,\"leaf\",default_class_probabilities)) # TODO REVIEW\n",
    "                if df.empty or len(np.unique(class_counts.values)) == 1:\n",
    "                    #print(\"case1: {0}\".format(default_class_probabilities))\n",
    "                    return nodeno, node_list.append((nodeno,\"leaf\",default_class_probabilities)) # TODO REVIEW\n",
    "                else:\n",
    "                    class_probabilities = [class_counts.get(label,0)/class_counts.sum() for label in self.labels]\n",
    "                    #class_probabilities = majority_class_prob(df)\n",
    "                    return nodeno, node_list.append((nodeno,\"leaf\",class_probabilities)) # TODO REVIEW\n",
    "                # Number of left instances < min_samples_split (default label)\n",
    "                #print(\"case1: {0}\".format(default_class_probabilities))\n",
    "               \n",
    "            #print(\"case0\")\n",
    "            return nodeno, node_list\n",
    "        \n",
    "        features = df_tmp.columns.drop([\"CLASS\",\"ID\"]) # Find the available features\n",
    "        \n",
    "        random_forest = []\n",
    "        for notree in range(notrees):\n",
    "            df_tree = generate_bootstrap(df_tmp) # Generate a new bootstrap from df_tmp\n",
    "            class_counts = df_tree.groupby(\"CLASS\").size() # Find the class counts\n",
    "            default_class_probabilities = [class_counts.get(label,0)/class_counts.sum() for label in self.labels] # Calculate the default class probabilities\n",
    "        \n",
    "            node_list = []             # Initialize node_list\n",
    "            greater_child_nodes = []   # Initialize greater_child_nodes\n",
    "            remaining_features = list(features.copy())    # Initialize remaining_features\n",
    "            nodeno,tree = divide_and_conquer(df_tmp, features, class_counts, default_class_probabilities, min_samples_split, random_features, 0)\n",
    "            tree = sorted(tree, key=lambda x: x[0]) # Sort tree by nodeno\n",
    "            \n",
    "            random_forest.append(tree)\n",
    "        \n",
    "        self.model = random_forest\n",
    "        #print(random_forest)\n",
    "        \n",
    "        \n",
    "    def predict(self, df):\n",
    "        # predictions: a dataframe with class labels as column names and the rows corresponding to\n",
    "        #              predictions with estimated class probabilities for each row in df, where the class probabilities\n",
    "        #              are the mean of all relative class frequencies in the leaves of the forest into which the instances in\n",
    "        #              df fall\n",
    "        #\n",
    "        # Hint 1: Drop any \"CLASS\" and \"ID\" columns first and then apply imputation and binning\n",
    "        # Hint 2: Iterate over the rows calling some sub-function, e.g., make_prediction(row), which for a test row\n",
    "        #         finds all leaf nodes and calculates the average of their class probabilities\n",
    "                # Hint 1: Drop any \"CLASS\" and \"ID\" columns first and then apply imputation and binning\n",
    "        \n",
    "        def make_prediction_randforest(nodeno,row,tree):\n",
    "            #print(\"Nodeno:{0} tree:{1} tree[nodeno][2]:{2}\".format(nodeno,tree[nodeno],tree[nodeno][2]))\n",
    "            if tree[nodeno][1] != \"leaf\":\n",
    "                feature = tree[nodeno][1]\n",
    "                for question in tree[nodeno][2].keys():\n",
    "                    #print(question)\n",
    "                    if eval(str(row[feature])+question):\n",
    "                        new_nodeno = tree[nodeno][2][question]\n",
    "                        \n",
    "                        return make_prediction_randforest(new_nodeno,row,tree)\n",
    "            else: \n",
    "                return tree[nodeno][2] \n",
    "            \n",
    "        df_tmp = df.drop(columns=[\"CLASS\",\"ID\"])\n",
    "        df_tmp = apply_imputation(df_tmp, self.imputation)\n",
    "        df_tmp = apply_bins(df_tmp,self.binning)\n",
    "        \n",
    "        predictions = pd.DataFrame(0,index=np.arange(len(df_tmp)), columns=self.labels).fillna(0)\n",
    "        forest = self.model\n",
    "        for tree in forest:\n",
    "            #print(tree)\n",
    "            for index, row in df_tmp.iterrows():\n",
    "                prediction = make_prediction_randforest(0,row,tree)\n",
    "                #print(prediction)\n",
    "                predictions.loc[index] += prediction\n",
    "        predictions = predictions/len(forest)\n",
    "        print(predictions)\n",
    "        return predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bootstrap(df):\n",
    "    idx = np.random.choice(len(df),len(df),replace=True)\n",
    "    df_out = df.iloc[idx].reset_index(drop=True)\n",
    "    return df_out\n",
    "\n",
    "# This function takes a dataframe and returns a mapping from the features to \n",
    "# the group sizes for each possible value of the feature\n",
    "def group_sizes_per_feature_randforest(df,features):\n",
    "    output = dict.fromkeys(features, {})                                          # Initialize dictionary from features\n",
    "    for col in features:                                                  # For each column excluding \"CLASS\" and \"ID\"\n",
    "        output[col] = {}                                                                         # Necessary to Assign Nested Keys and Values in Dictionaries (https://stackoverflow.com/questions/22455384/assign-nested-keys-and-values-in-dictionaries)\n",
    "        for value in df[col].unique():                                                           # For each value of the column\n",
    "            lower_equal_cases_series = df[df[col] <= value].groupby(\"CLASS\").size()      # Find those instances that are lower or equal than the value and group them by CLASS\n",
    "            greater_cases_series = df[df[col] > value].groupby(\"CLASS\").size()           # Find those instances that are greater than the value and group them by CLASS\n",
    "        \n",
    "            le = {label:lower_equal_cases_series.get(label,0) for label in df[\"CLASS\"].unique()} # TODO CHANGE CLASS FOR LABELS Transform lower_equal_cases_series to a structured dictionary where empty classes have a 0 as value\n",
    "            g = {label:greater_cases_series.get(label,0) for label in df[\"CLASS\"].unique()}      # TODO CHANGE CLASS FOR LABELS Transform greater_cases_series to a structured dictionary where empty classes have a 0 as value\n",
    "\n",
    "            output[col][value] = [le, g]                                                         # Update the output\n",
    "                        \n",
    "    return output\n",
    "\n",
    "def entropy(class_counts):\n",
    "# Computes entropy from class_counts\n",
    "    #print(class_counts)\n",
    "    non_zero_labels_count = sum(np.fromiter(class_counts.values(), dtype=int) >= 0)\n",
    "    if non_zero_labels_count <= 1:\n",
    "        return 0\n",
    "    \n",
    "    num_instances = sum(class_counts.values())\n",
    "    if num_instances <= 1:\n",
    "        return 0\n",
    "    \n",
    "    probs = list(class_counts.values())/sum(class_counts.values())\n",
    "    #probs = np.array(list(class_counts.values()))/sum(class_counts.values())\n",
    "    return sum([0 if i == 0 else -i * np.log2(i) for i in probs])\n",
    "\n",
    "def information_content(group_sizes,class_counts,features): # TODO: class_counts not used and features used ??!!\n",
    "    res_inf = dict.fromkeys(features, {})\n",
    "    for feature in group_sizes.keys():\n",
    "        res_inf[feature] = {}\n",
    "        for value in group_sizes[feature].keys():\n",
    "            dict_lower_equal = group_sizes.get(feature).get(value)[0]\n",
    "            dict_greater = group_sizes.get(feature).get(value)[1]\n",
    "\n",
    "            lower_equal_instances = sum(dict_lower_equal.values())\n",
    "            greater_instances = sum(dict_greater.values())\n",
    "            total_instances = lower_equal_instances + greater_instances # TODO: Check if sum(class_counts) == lower_equal_instances + greater_instances\n",
    "\n",
    "            lower_equal_entropy = entropy(dict_lower_equal)\n",
    "            greater_entropy = entropy(dict_greater)\n",
    "\n",
    "            res_inf[feature][value] = (lower_equal_instances/total_instances)*lower_equal_entropy + (greater_instances/total_instances)*greater_entropy\n",
    "    return res_inf\n",
    "\n",
    "def find_best_question(res_inf):\n",
    "    lowest_information = 20000\n",
    "    for feature in res_inf.keys():\n",
    "        for value in res_inf[feature].keys():\n",
    "            res_inf_value = res_inf[feature][value]\n",
    "            if res_inf_value < lowest_information:\n",
    "                lowest_information = res_inf_value\n",
    "                feature_out = feature\n",
    "                value_out = value\n",
    "    #print(\"Feature:{0} Value:{1} ResInf:{2}\".format(feature_out,value_out,lowest_information))            \n",
    "    return feature_out,value_out\n",
    "\n",
    "#SPLIT\n",
    "def split(df,feature,value):\n",
    "    lower_equal_cases = df[df[feature] <= value].drop(columns=feature)\n",
    "    greater_cases = df[df[feature] > value].drop(columns=feature)\n",
    "    return lower_equal_cases, greater_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe'], dtype='object')\n",
      "['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe']\n",
      "['Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe']\n",
      "['Si' 'Na']\n"
     ]
    }
   ],
   "source": [
    "glass_train_df = pd.read_csv(\"glass_train.txt\")\n",
    "df = glass_train_df.copy()\n",
    "features = df.columns.drop([\"CLASS\",\"ID\"])\n",
    "print(features)\n",
    "remaining_features = list(features.copy())\n",
    "print(remaining_features)\n",
    "remaining_features.remove(\"RI\")\n",
    "print(remaining_features)\n",
    "features = np.random.choice(features,2)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (1, 1): 2.01 s.\n",
      "            1         2         3         5         6         7\n",
      "0    0.253086  0.459137  0.025748  0.056149  0.024150  0.181729\n",
      "1    0.335653  0.280063  0.111106  0.092192  0.049631  0.131355\n",
      "2    0.494209  0.222733  0.138573  0.017192  0.033933  0.093360\n",
      "3    0.304236  0.304411  0.049577  0.048015  0.038587  0.255176\n",
      "4    0.220953  0.597535  0.055325  0.055543  0.009756  0.060887\n",
      "..        ...       ...       ...       ...       ...       ...\n",
      "102  0.220953  0.597535  0.055325  0.055543  0.009756  0.060887\n",
      "103  0.250953  0.557535  0.065325  0.055543  0.009756  0.060887\n",
      "104  0.369993  0.288956  0.056243  0.050136  0.034041  0.200631\n",
      "105  0.192344  0.478542  0.043490  0.207192  0.062964  0.015468\n",
      "106  0.388678  0.395807  0.058195  0.064164  0.029403  0.063753\n",
      "\n",
      "[107 rows x 6 columns]\n",
      "Testing time (1, 1): 0.90 s.\n",
      "Training time (1, 2): 3.11 s.\n",
      "            1         2         3         5         6         7\n",
      "0    0.359497  0.486196  0.079894  0.008249  0.000000  0.066163\n",
      "1    0.293116  0.364679  0.078177  0.128065  0.064638  0.071324\n",
      "2    0.499843  0.295619  0.110193  0.008621  0.028949  0.056775\n",
      "3    0.469843  0.332285  0.120193  0.008621  0.028949  0.040109\n",
      "4    0.291598  0.442542  0.071941  0.113793  0.006897  0.073228\n",
      "..        ...       ...       ...       ...       ...       ...\n",
      "102  0.291598  0.542542  0.071941  0.013793  0.006897  0.073228\n",
      "103  0.345170  0.561138  0.071941  0.000000  0.000000  0.021750\n",
      "104  0.473297  0.337740  0.110739  0.013166  0.028949  0.036109\n",
      "105  0.053879  0.589358  0.010345  0.293065  0.046456  0.006897\n",
      "106  0.445081  0.359904  0.110193  0.008621  0.028949  0.047252\n",
      "\n",
      "[107 rows x 6 columns]\n",
      "Testing time (1, 2): 1.06 s.\n",
      "Training time (1, 5): 7.06 s.\n",
      "            1         2         3         5         6         7\n",
      "0    0.269147  0.545059  0.076813  0.062046  0.033566  0.013369\n",
      "1    0.330620  0.368070  0.089040  0.031481  0.104015  0.076774\n",
      "2    0.518871  0.252590  0.106729  0.031481  0.045833  0.044495\n",
      "3    0.576434  0.269394  0.113497  0.009259  0.011111  0.020305\n",
      "4    0.258627  0.556048  0.084025  0.057101  0.018182  0.026018\n",
      "..        ...       ...       ...       ...       ...       ...\n",
      "102  0.258627  0.556048  0.084025  0.057101  0.018182  0.026018\n",
      "103  0.288627  0.516048  0.094025  0.057101  0.018182  0.026018\n",
      "104  0.634995  0.211944  0.102386  0.009259  0.011111  0.030305\n",
      "105  0.114815  0.723194  0.031019  0.031481  0.085833  0.013657\n",
      "106  0.347868  0.379417  0.102866  0.082131  0.051515  0.036203\n",
      "\n",
      "[107 rows x 6 columns]\n",
      "Testing time (1, 5): 0.89 s.\n",
      "Training time (2, 1): 1.71 s.\n",
      "            1         2         3         5         6         7\n",
      "0    0.239670  0.601626  0.063287  0.025970  0.008913  0.060534\n",
      "1    0.348011  0.317648  0.080916  0.111332  0.104659  0.037433\n",
      "2    0.542333  0.194102  0.081536  0.056332  0.055628  0.070069\n",
      "3    0.415719  0.280474  0.105556  0.051306  0.064541  0.082404\n",
      "4    0.159389  0.506907  0.033207  0.098167  0.006897  0.195434\n",
      "..        ...       ...       ...       ...       ...       ...\n",
      "102  0.159389  0.586907  0.053207  0.048167  0.006897  0.145434\n",
      "103  0.258230  0.636024  0.051671  0.026620  0.005882  0.021573\n",
      "104  0.453598  0.276687  0.098738  0.046760  0.050905  0.073313\n",
      "105  0.280168  0.378237  0.044053  0.151332  0.071326  0.074884\n",
      "106  0.388173  0.344038  0.107995  0.056523  0.049511  0.053759\n",
      "\n",
      "[107 rows x 6 columns]\n",
      "Testing time (2, 1): 0.86 s.\n",
      "Training time (2, 2): 2.82 s.\n",
      "            1         2         3         5         6         7\n",
      "0    0.335908  0.451626  0.111090  0.032488  0.018415  0.050472\n",
      "1    0.338497  0.212977  0.107081  0.048723  0.137609  0.155113\n",
      "2    0.469017  0.267988  0.106955  0.048723  0.054023  0.053293\n",
      "3    0.454628  0.295060  0.111921  0.035592  0.034831  0.067969\n",
      "4    0.268098  0.557526  0.043240  0.037644  0.000000  0.093491\n",
      "..        ...       ...       ...       ...       ...       ...\n",
      "102  0.268098  0.557526  0.043240  0.037644  0.000000  0.093491\n",
      "103  0.311432  0.596011  0.043240  0.024008  0.000000  0.025310\n",
      "104  0.454628  0.295060  0.111921  0.035592  0.034831  0.067969\n",
      "105  0.155907  0.457605  0.039208  0.232056  0.094023  0.021201\n",
      "106  0.352339  0.402783  0.075781  0.068564  0.054023  0.046510\n",
      "\n",
      "[107 rows x 6 columns]\n",
      "Testing time (2, 2): 0.90 s.\n",
      "Training time (2, 5): 6.55 s.\n",
      "            1         2         3         5         6         7\n",
      "0    0.327565  0.565985  0.089570  0.006452  0.000000  0.010428\n",
      "1    0.424827  0.303060  0.117588  0.030065  0.048247  0.076213\n",
      "2    0.471744  0.314659  0.125320  0.030065  0.030065  0.028146\n",
      "3    0.503755  0.345611  0.114209  0.007843  0.007843  0.020739\n",
      "4    0.329047  0.462865  0.084385  0.034530  0.006897  0.082276\n",
      "..        ...       ...       ...       ...       ...       ...\n",
      "102  0.329047  0.462865  0.084385  0.034530  0.006897  0.082276\n",
      "103  0.329047  0.542175  0.084385  0.020737  0.000000  0.023655\n",
      "104  0.518906  0.323389  0.121280  0.007843  0.007843  0.020739\n",
      "105  0.077614  0.785458  0.019172  0.080065  0.030065  0.007625\n",
      "106  0.426086  0.357096  0.107673  0.044351  0.030065  0.034729\n",
      "\n",
      "[107 rows x 6 columns]\n",
      "Testing time (2, 5): 0.89 s.\n",
      "Training time (5, 1): 1.87 s.\n",
      "            1         2         3         5         6         7\n",
      "0    0.419746  0.402108  0.057290  0.028283  0.003030  0.089542\n",
      "1    0.283424  0.220933  0.099538  0.135668  0.132526  0.127912\n",
      "2    0.553212  0.142417  0.108726  0.055213  0.023840  0.116591\n",
      "3    0.361745  0.418003  0.071329  0.030682  0.016667  0.101574\n",
      "4    0.187087  0.426420  0.040479  0.085476  0.011244  0.249294\n",
      "..        ...       ...       ...       ...       ...       ...\n",
      "102  0.187087  0.426420  0.040479  0.085476  0.011244  0.249294\n",
      "103  0.263632  0.571770  0.051169  0.048701  0.000000  0.064729\n",
      "104  0.419746  0.402108  0.057290  0.028283  0.003030  0.089542\n",
      "105  0.224044  0.317006  0.062497  0.305033  0.067022  0.024397\n",
      "106  0.298737  0.474334  0.064087  0.063915  0.023840  0.075086\n",
      "\n",
      "[107 rows x 6 columns]\n",
      "Testing time (5, 1): 0.99 s.\n",
      "Training time (5, 2): 3.13 s.\n",
      "            1         2         3         5         6         7\n",
      "0    0.327806  0.449889  0.053717  0.064870  0.015152  0.088566\n",
      "1    0.308823  0.284297  0.079075  0.075000  0.144432  0.108373\n",
      "2    0.558767  0.198445  0.106313  0.062500  0.009302  0.064672\n",
      "3    0.419899  0.356416  0.093109  0.018182  0.015363  0.097031\n",
      "4    0.144673  0.550060  0.119171  0.066377  0.027099  0.092621\n",
      "..        ...       ...       ...       ...       ...       ...\n",
      "102  0.144673  0.550060  0.119171  0.066377  0.027099  0.092621\n",
      "103  0.203244  0.567942  0.114886  0.052584  0.020202  0.041143\n",
      "104  0.484356  0.290522  0.090552  0.026176  0.015363  0.093031\n",
      "105  0.104776  0.575213  0.014897  0.151782  0.103333  0.050000\n",
      "106  0.217642  0.486668  0.100657  0.115084  0.029504  0.050445\n",
      "\n",
      "[107 rows x 6 columns]\n",
      "Testing time (5, 2): 0.88 s.\n",
      "Training time (5, 5): 7.68 s.\n",
      "            1         2         3         5         6         7\n",
      "0    0.400641  0.451481  0.074981  0.036364  0.018182  0.018351\n",
      "1    0.374051  0.315395  0.112355  0.000000  0.078586  0.119614\n",
      "2    0.550138  0.287165  0.125439  0.000000  0.000000  0.037258\n",
      "3    0.538337  0.295860  0.142830  0.000000  0.000000  0.022973\n",
      "4    0.290080  0.568369  0.070695  0.036364  0.018182  0.016310\n",
      "..        ...       ...       ...       ...       ...       ...\n",
      "102  0.290080  0.568369  0.070695  0.036364  0.018182  0.016310\n",
      "103  0.290080  0.568369  0.070695  0.036364  0.018182  0.016310\n",
      "104  0.595716  0.292298  0.095403  0.000000  0.000000  0.016583\n",
      "105  0.060000  0.494004  0.008571  0.379567  0.020000  0.037857\n",
      "106  0.355023  0.469844  0.098052  0.036364  0.018182  0.022536\n",
      "\n",
      "[107 rows x 6 columns]\n",
      "Testing time (5, 5): 1.21 s.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Brier score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"3\" valign=\"top\">1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.526319</td>\n",
       "      <td>0.828355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.691589</td>\n",
       "      <td>0.488018</td>\n",
       "      <td>0.893918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.691589</td>\n",
       "      <td>0.447830</td>\n",
       "      <td>0.869231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"3\" valign=\"top\">2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.524655</td>\n",
       "      <td>0.855754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.700935</td>\n",
       "      <td>0.512532</td>\n",
       "      <td>0.852791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.691589</td>\n",
       "      <td>0.462620</td>\n",
       "      <td>0.863398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"3\" valign=\"top\">5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.626168</td>\n",
       "      <td>0.531459</td>\n",
       "      <td>0.800847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.691589</td>\n",
       "      <td>0.499402</td>\n",
       "      <td>0.842670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.471342</td>\n",
       "      <td>0.882817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Accuracy  Brier score       AUC\n",
       "1 1  0.616822     0.526319  0.828355\n",
       "  2  0.691589     0.488018  0.893918\n",
       "  5  0.691589     0.447830  0.869231\n",
       "2 1  0.644860     0.524655  0.855754\n",
       "  2  0.700935     0.512532  0.852791\n",
       "  5  0.691589     0.462620  0.863398\n",
       "5 1  0.626168     0.531459  0.800847\n",
       "  2  0.691589     0.499402  0.842670\n",
       "  5  0.719626     0.471342  0.882817"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass_train_df = pd.read_csv(\"glass_train.txt\")\n",
    "\n",
    "glass_test_df = pd.read_csv(\"glass_test.txt\")\n",
    "\n",
    "forest_model = DecisionForest()\n",
    "\n",
    "test_labels = glass_test_df[\"CLASS\"]\n",
    "\n",
    "min_samples_split_values = [1,2,5]\n",
    "random_features_values = [1,2,5]\n",
    "\n",
    "parameters = [(min_samples_split,random_features) for min_samples_split in min_samples_split_values \n",
    "              for random_features in random_features_values]\n",
    "\n",
    "results = np.empty((len(parameters),3))\n",
    "\n",
    "for i in range(len(parameters)):\n",
    "    t0 = time.perf_counter()\n",
    "    forest_model.fit(glass_train_df,min_samples_split=parameters[i][0],random_features=parameters[i][1])\n",
    "    print(\"Training time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    t0 = time.perf_counter()\n",
    "    predictions = forest_model.predict(glass_test_df)\n",
    "    print(\"Testing time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    results[i] = [accuracy(predictions,test_labels),brier_score(predictions,test_labels),\n",
    "                  auc(predictions,test_labels)] # Assuming that you have defined auc - remove otherwise\n",
    "\n",
    "results = pd.DataFrame(results,index=pd.MultiIndex.from_product([min_samples_split_values,random_features_values]),\n",
    "                       columns=[\"Accuracy\",\"Brier score\",\"AUC\"])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.79\n",
      "AUC on training set: 0.94\n",
      "Brier score on training set: 0.39\n"
     ]
    }
   ],
   "source": [
    "train_labels = glass_train_df[\"CLASS\"]\n",
    "forest_model.fit(glass_train_df,min_samples_split=1)\n",
    "predictions = forest_model.predict(glass_train_df)\n",
    "print(\"Accuracy on training set: {0:.2f}\".format(accuracy(predictions,train_labels)))\n",
    "print(\"AUC on training set: {0:.2f}\".format(auc(predictions,train_labels)))\n",
    "print(\"Brier score on training set: {0:.2f}\".format(brier_score(predictions,train_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment on assumptions, things that do not work properly, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
